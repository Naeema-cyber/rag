{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae13830",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dd77c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "print(\"API Key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fca0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9169307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naheemot Adenike Adebiyi\n",
      " \n",
      "AI & Machine Learning Engineer | Lagos, Nigeria\n",
      "+234 810 120 5765 | naeemaadenike@gmail.com | LinkedIn\n",
      "Professional Summary\n",
      "Entry-level AI and Machine Learning Engineer with strong hands-on experience in building\n",
      "end-to-end machine learning solutions. Skilled in transforming data into actionable insights and\n",
      "deploying models via APIs to support business decision-making.\n",
      "Technical Skills\n",
      "1\n",
      "Python, SQL\n",
      "2\n",
      "Machine Learning & Artificial Intelligence\n",
      "3\n",
      "Data Analysis & Feature Engineering\n",
      "4\n",
      "Model Evaluation & Optimization\n",
      "5\n",
      "FastAPI & RESTful APIs\n",
      "Projects\n",
      "Loan Approval Prediction System\n",
      "1\n",
      "Built a machine learning model to predict loan approval outcomes using customer financial\n",
      "data.\n",
      "2\n",
      "Performed data cleaning, exploratory data analysis, and feature engineering to improve model\n",
      "accuracy.\n",
      "3\n",
      "Trained and evaluated multiple machine learning algorithms to select the best-performing\n",
      "model.\n",
      "4\n",
      "Deployed the trained model using FastAPI, enabling real-time loan approval predictions via\n",
      "REST API.\n",
      "5\n",
      "Designed the system to support data-driven lending decisions and reduce financial risk.\n",
      "Tools: Python, Pandas, Scikit-learn, SQL, FastAPI\n",
      "Experience\n",
      "Transitioned into the tech industry with a strong focus on practical machine learning projects,\n",
      "continuous learning, and real-world business problem solving.\n",
      "Education\n",
      "Bachelor of Science (B.Sc.)\n",
      "University of Port Harcourt — 2017\n",
      "\n",
      "Naheemot Adenike Adebiyi\n",
      " \n",
      "AI & Machine Learning Engineer | Lagos, Nigeria\n",
      "+234 810 120 5765 | naeemaadenike@gmail.com | LinkedIn\n",
      "Professional Summary\n",
      "Entry-level AI and Machine Learning Engineer with strong hands-on experience in building\n",
      "end-to-end machine learning solutions. Skilled in transforming data into actionable insights and\n",
      "deploying models via APIs to support business decision-making.\n",
      "Technical Skills\n",
      "1\n",
      "Python, SQL\n",
      "2\n",
      "Machine Learning & Artificial Intelligence\n",
      "3\n",
      "Data Analysis & Feature Engineering\n",
      "4\n",
      "Model Evaluation & Optimization\n",
      "5\n",
      "FastAPI & RESTful APIs\n",
      "Projects\n",
      "Loan Approval Prediction System\n",
      "1\n",
      "Built a machine learning model to predict loan approval outcomes using customer financial\n",
      "data.\n",
      "2\n",
      "Performed data cleaning, exploratory data analysis, and feature engineering to improve model\n",
      "accuracy.\n",
      "3\n",
      "Trained and evaluated multiple machine learning algorithms to select the best-performing\n",
      "model.\n",
      "4\n",
      "Deployed the trained model using FastAPI, enabling real-time loan approval predictions via\n",
      "REST API.\n",
      "5\n",
      "Designed the system to support data-driven lending decisions and reduce financial risk.\n",
      "Tools: Python, Pandas, Scikit-learn, SQL, FastAPI\n",
      "Experience\n",
      "Transitioned into the tech industry with a strong focus on practical machine learning projects,\n",
      "continuous learning, and real-world business problem solving.\n",
      "Education\n",
      "Bachelor of Science (B.Sc.)\n",
      "University of Port Harcourt — 2017\n",
      "Certifications\n",
      "1\n",
      "3MTT Program\n",
      "2\n",
      "ALX Diploma of Education\n",
      "3\n",
      "LinkedIn Generative AI Certification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the file\n",
    "file_path = r\"C:\\Users\\Dell\\Downloads\\Naheemot_Adebiyi_ML_CV.pdf\"\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "pages = \"\"\n",
    "\n",
    "with open(file_path, \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    num_pages = len(reader.pages)\n",
    "    for page_num in reader.pages:\n",
    "        pages += page_num.extract_text()\n",
    "        print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c079a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "\n",
      "Chunk 1 (399 chars):\n",
      "Naheemot Adenike Adebiyi\n",
      " \n",
      "AI & Machine Learning Engineer | Lagos, Nigeria\n",
      "+234 810 120 5765 | naeemaadenike@gmail.com | LinkedIn\n",
      "Professional Summary\n",
      "Entry-level AI and Machine Learning Engineer with strong hands-on experience in building\n",
      "end-to-end machine learning solutions. Skilled in transforming data into actionable insights and\n",
      "deploying models via APIs to support business decision-making.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 2 (416 chars):\n",
      "Technical Skills\n",
      "1\n",
      "Python, SQL\n",
      "2\n",
      "Machine Learning & Artificial Intelligence\n",
      "3\n",
      "Data Analysis & Feature Engineering\n",
      "4\n",
      "Model Evaluation & Optimization\n",
      "5\n",
      "FastAPI & RESTful APIs\n",
      "Projects\n",
      "Loan Approval Prediction System\n",
      "1\n",
      "Built a machine learning model to predict loan approval outcomes using customer financial\n",
      "data. 2\n",
      "Performed data cleaning, exploratory data analysis, and feature engineering to improve model\n",
      "accuracy.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 3 (290 chars):\n",
      "3\n",
      "Trained and evaluated multiple machine learning algorithms to select the best-performing\n",
      "model. 4\n",
      "Deployed the trained model using FastAPI, enabling real-time loan approval predictions via\n",
      "REST API. 5\n",
      "Designed the system to support data-driven lending decisions and reduce financial risk.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 4 (387 chars):\n",
      "Tools: Python, Pandas, Scikit-learn, SQL, FastAPI\n",
      "Experience\n",
      "Transitioned into the tech industry with a strong focus on practical machine learning projects,\n",
      "continuous learning, and real-world business problem solving. Education\n",
      "Bachelor of Science (B.Sc.)\n",
      "University of Port Harcourt — 2017\n",
      "Certifications\n",
      "1\n",
      "3MTT Program\n",
      "2\n",
      "ALX Diploma of Education\n",
      "3\n",
      "LinkedIn Generative AI Certification\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_sentences(text, max_chunk_size=500):\n",
    "    # Simple sentence splitting (split on . ! ?)\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Check if adding this sentence would exceed max size\n",
    "        if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:\n",
    "            # Save current chunk and start new one\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            # Add sentence to current chunk\n",
    "            current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_sentences(pages, max_chunk_size=500)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac824b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1496 documents into 10 chunks\n",
      "Chunk 1 (150 chars): Naheemot Adenike Adebiyi\n",
      " \n",
      "AI & Machine Learning Engineer | Lagos, Nigeria\n",
      "+234 810 120 5765 | naeemaadenike@gmail.com | LinkedIn\n",
      "Professional Summary\n",
      "\n",
      "Chunk 2 (185 chars): Entry-level AI and Machine Learning Engineer with strong hands-on experience in building\n",
      "end-to-end machine learning solutions. Skilled in transforming data into actionable insights and\n",
      "\n",
      "Chunk 3 (178 chars): deploying models via APIs to support business decision-making.\n",
      "Technical Skills\n",
      "1\n",
      "Python, SQL\n",
      "2\n",
      "Machine Learning & Artificial Intelligence\n",
      "3\n",
      "Data Analysis & Feature Engineering\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_text(pages)\n",
    "\n",
    "print(f\"Split {len(pages)} documents into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"Chunk {i+1} ({len(chunk)} chars): {chunk}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e77022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n",
      "First 5 values: [0.01047521736472845, -0.049979958683252335, -0.01698615960776806, 0.025253426283597946, 0.0020354539155960083]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key = api_key\n",
    ")\n",
    "\n",
    "# Test embedding\n",
    "test_embedding = embeddings.embed_query(\"Who is Naheemot Adebiyi?\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "print(f\"First 5 values: {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98d6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store created with 10 chunks\n",
      "\n",
      "Query: Who is Naheemot Adebiyi?\n",
      "\n",
      "Result 1: Naheemot Adenike Adebiyi\n",
      " \n",
      "AI & Machine Learning Engineer | Lagos, Nigeria\n",
      "+234 810 120 5765 | naeemaadenike@gmail.com | LinkedIn\n",
      "Professional Summary\n",
      "\n",
      "Result 2: continuous learning, and real-world business problem solving.\n",
      "Education\n",
      "Bachelor of Science (B.Sc.)\n",
      "University of Port Harcourt — 2017\n",
      "Certifications\n",
      "1\n",
      "3MTT Program\n",
      "2\n",
      "ALX Diploma of Education\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Create vector store from documents\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "print(f\"✅ Vector store created with {len(chunks)} chunks\")\n",
    "\n",
    "# Test similarity search\n",
    "query = \"Who is Naheemot Adebiyi?\"\n",
    "results = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4eec606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG chain created\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Create prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer using ONLY the provided context.\"),\n",
    "    (\"human\", \"{question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ RAG chain created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77ce2b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naheemot Adenike Adebiyi is an AI & Machine Learning Engineer based in Lagos, Nigeria.\n"
     ]
    }
   ],
   "source": [
    "# Query the chain\n",
    "response = rag_chain.invoke(\"Who is Naheemot Adebiyi?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfb35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Create a custom prompt with specific instructions\n",
    "custom_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a precise assistant. If you don't know the answer based on the context, say 'I don't know'.\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Build chain with custom prompt\n",
    "custom_rag = (\n",
    "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Query\n",
    "response = custom_rag.invoke(\"What is vector search?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63ad7fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversational chain created\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Store for chat histories\n",
    "chat_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_store[session_id]\n",
    "\n",
    "# Create conversational prompt\n",
    "conv_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer using the context provided.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Build base chain\n",
    "conv_chain_base = (\n",
    "    RunnableParallel(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        question=lambda x: x[\"question\"],\n",
    "        chat_history=lambda x: x.get(\"chat_history\", [])\n",
    "    )\n",
    "    | conv_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Wrap with message history\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    conv_chain_base,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "print(\"✅ Conversational chain created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cddbcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Who is Naheemot Adebiyi?\n",
      "A1: Naheemot Adenike Adebiyi is an AI & Machine Learning Engineer based in Lagos, Nigeria. She graduated with a Bachelor of Science degree from the University of Port Harcourt in 2017 and holds certifications in the 3MTT Program and ALX Diploma of Education.\n",
      "\n",
      "Q2: What does she do?\n",
      "A2: Naheemot Adenike Adebiyi is an AI & Machine Learning Engineer who specializes in solving real-world business problems through continuous learning and application of artificial intelligence and machine learning techniques.\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "response1 = conv_chain.invoke(\n",
    "    {\"question\": \"Who is Naheemot Adebiyi?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "print(f\"Q1: Who is Naheemot Adebiyi?\")\n",
    "print(f\"A1: {response1}\\n\")\n",
    "\n",
    "# Follow-up question (remembers context)\n",
    "response2 = conv_chain.invoke(\n",
    "    {\"question\": \"What does she do?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "print(f\"Q2: What does she do?\")\n",
    "print(f\"A2: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e826df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History:\n",
      "\n",
      "human: Who is Naheemot Adebiyi?\n",
      "\n",
      "ai: Naheemot Adenike Adebiyi is an AI & Machine Learning Engineer based in Lagos, Nigeria. She graduated with a Bachelor of Science degree from the University of Port Harcourt in 2017 and holds certifications in the 3MTT Program and ALX Diploma of Education.\n",
      "\n",
      "human: What does she do?\n",
      "\n",
      "ai: Naheemot Adenike Adebiyi is an AI & Machine Learning Engineer who specializes in solving real-world business problems through continuous learning and application of artificial intelligence and machine learning techniques.\n"
     ]
    }
   ],
   "source": [
    "# View chat history\n",
    "session = get_session_history(\"session1\")\n",
    "print(\"Chat History:\")\n",
    "for msg in session.messages:\n",
    "    print(f\"\\n{msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "318a36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store saved\n",
      "✅ Vector store loaded\n",
      "\n",
      "Test result: 3\n",
      "LinkedIn Generative AI Certification\n"
     ]
    }
   ],
   "source": [
    "# Save vector store\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"✅ Vector store saved\")\n",
    "\n",
    "# Load vector store\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "print(\"✅ Vector store loaded\")\n",
    "\n",
    "# Test\n",
    "test_results = loaded_vectorstore.similarity_search(\"LangChain\", k=1)\n",
    "print(f\"\\nTest result: {test_results[0].page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
